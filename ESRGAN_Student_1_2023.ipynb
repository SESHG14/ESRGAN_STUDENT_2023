{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1eu8PjPUb-Jkwiqcbdk-3KfJEb-g9vVhE",
      "authorship_tag": "ABX9TyPMhhcIyMsCwFf1VsMMtFrJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SESHG14/ESRGAN_STUDENT_2023/blob/main/ESRGAN_Student_1_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training a Student Network using Knowledge Distillation\n",
        "\n",
        "- Using a reduced ESRGAN model -> 8 residual layers instead of 16.\n",
        "- Same structure as Teacher model."
      ],
      "metadata": {
        "id": "nVvQP1XKk_s2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbQujP7mk3gG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras import layers, Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import numpy as np\n",
        "from keras import Model\n",
        "from keras.layers import Conv2D, PReLU,BatchNormalization, Flatten\n",
        "from keras.layers import UpSampling2D, LeakyReLU, Dense, Input, add\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Student Model Structure Functions:"
      ],
      "metadata": {
        "id": "N1vKLZCZml_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def res_block(ip):\n",
        "\n",
        "    temp = ip\n",
        "\n",
        "    # 1 - initial\n",
        "    res_model = Conv2D(64, (3,3), padding = \"same\")(ip)\n",
        "    res_model = LeakyReLU(alpha=0.2)(res_model)\n",
        "    res_model = add([temp,res_model])\n",
        "\n",
        "    # 2\n",
        "    temp = res_model\n",
        "    res_model = Conv2D(64, (3,3), padding = \"same\")(res_model)\n",
        "    res_model = LeakyReLU(alpha=0.2)(res_model)\n",
        "    res_model = add([temp,res_model])\n",
        "    # 3\n",
        "    temp = res_model\n",
        "    res_model = Conv2D(64, (3,3), padding = \"same\")(res_model)\n",
        "    res_model = LeakyReLU(alpha=0.2)(res_model)\n",
        "    res_model = add([temp,res_model])\n",
        "    # 4\n",
        "    temp = res_model\n",
        "    res_model = Conv2D(64, (3,3), padding = \"same\")(res_model)\n",
        "    res_model = LeakyReLU(alpha=0.2)(res_model)\n",
        "    res_model = add([temp,res_model])\n",
        "    # Final Convolution\n",
        "    res_model = Conv2D(64, (3,3), padding = \"same\")(res_model)\n",
        "\n",
        "    #res_model = Conv2D(64, (3,3), padding = \"same\")(res_model)\n",
        "    res_model = BatchNormalization(momentum = 0.5)(res_model)\n",
        "\n",
        "    return add([ip,res_model])\n",
        "\n",
        "def res_in_res_block(ip):\n",
        "\n",
        "    #1\n",
        "    compound_res = res_block(ip)\n",
        "    #2\n",
        "    compound_res = res_block(compound_res)\n",
        "    #3\n",
        "    compound_res = res_block(compound_res)\n",
        "\n",
        "    return add([ip,compound_res])\n",
        "\n",
        "\n",
        "def upscale_block(ip):\n",
        "\n",
        "    up_model = Conv2D(256, (3,3), padding=\"same\")(ip)\n",
        "    up_model = UpSampling2D( size = 2 )(up_model)\n",
        "    #up_model = PReLU(shared_axes=[1,2])(up_model)\n",
        "    up_model = LeakyReLU(alpha=0.2)(up_model)\n",
        "\n",
        "    return up_model\n",
        "\n",
        "# Proposed ESRGAN Generator\n",
        "def create_gen(gen_ip, num_res_block):\n",
        "    layers = Conv2D(64, (9,9), padding=\"same\")(gen_ip)\n",
        "    #layers = PReLU(shared_axes=[1,2])(layers)\n",
        "    layers = LeakyReLU(alpha=0.2)(layers)\n",
        "\n",
        "    temp = layers\n",
        "\n",
        "    for i in range(num_res_block):\n",
        "        layers = res_in_res_block(layers)\n",
        "\n",
        "    layers = Conv2D(64, (3,3), padding=\"same\")(layers)\n",
        "    layers = BatchNormalization(momentum=0.5)(layers)\n",
        "    layers = add([layers,temp])\n",
        "\n",
        "    layers = upscale_block(layers)\n",
        "    layers = upscale_block(layers)\n",
        "\n",
        "    #layers = Conv2D(64, (3,3), padding=\"same\")(layers)\n",
        "    op = Conv2D(3, (9,9), padding=\"same\")(layers)\n",
        "\n",
        "    return Model(inputs=gen_ip, outputs=op)\n",
        "\n",
        "\n",
        "#Descriminator block that will be used to construct the discriminator\n",
        "def discriminator_block(ip, filters, strides=1, bn=True):\n",
        "\n",
        "    disc_model = Conv2D(filters, (3,3), strides = strides, padding=\"same\")(ip)\n",
        "\n",
        "    if bn:\n",
        "        disc_model = BatchNormalization( momentum=0.8 )(disc_model)\n",
        "\n",
        "    disc_model = LeakyReLU( alpha=0.2 )(disc_model)\n",
        "\n",
        "    return disc_model\n",
        "\n",
        "#Descriminartor, as described in the original paper\n",
        "def create_disc(disc_ip):\n",
        "\n",
        "    df = 64\n",
        "\n",
        "    d1 = discriminator_block(disc_ip, df, bn=False)\n",
        "    d2 = discriminator_block(d1, df, strides=2)\n",
        "    d3 = discriminator_block(d2, df*2)\n",
        "    d4 = discriminator_block(d3, df*2, strides=2)\n",
        "    d5 = discriminator_block(d4, df*4)\n",
        "    d6 = discriminator_block(d5, df*4, strides=2)\n",
        "    d7 = discriminator_block(d6, df*8)\n",
        "    d8 = discriminator_block(d7, df*8, strides=2)\n",
        "\n",
        "    d8_5 = Flatten()(d8)\n",
        "    d9 = Dense(df*16)(d8_5)\n",
        "    d10 = LeakyReLU(alpha=0.2)(d9)\n",
        "    validity = Dense(1, activation='sigmoid')(d10)\n",
        "\n",
        "    return Model(disc_ip, validity)\n",
        "\n",
        "#VGG19 for the feature map obtained by the j-th convolution (after activation)\n",
        "#before the i-th maxpooling layer within the VGG19 network.(as described in the paper)\n",
        "#Build a pre-trained VGG19 model that outputs image features extracted at the\n",
        "# third block of the model\n",
        "# VGG architecture: https://github.com/keras-team/keras/blob/master/keras/applications/vgg19.py\n",
        "from keras.applications import VGG19\n",
        "\n",
        "def build_vgg(hr_shape):\n",
        "\n",
        "    vgg = VGG19(weights=\"imagenet\",include_top=False, input_shape=hr_shape)\n",
        "\n",
        "    return Model(inputs=vgg.inputs, outputs=vgg.layers[10].output)\n",
        "\n",
        "#Combined model\n",
        "def create_comb(gen_model, disc_model, vgg, lr_ip, hr_ip):\n",
        "    gen_img = gen_model(lr_ip)\n",
        "\n",
        "    gen_features = vgg(gen_img)\n",
        "\n",
        "    disc_model.trainable = False\n",
        "    validity = disc_model(gen_img)\n",
        "\n",
        "    return Model(inputs=[lr_ip, hr_ip], outputs=[validity, gen_features])"
      ],
      "metadata": {
        "id": "2fprhWutmqp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LR SCHEDULERS for Gen and Disc"
      ],
      "metadata": {
        "id": "e26ifIoinY8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def MultiStepLR(initial_learning_rate, lr_steps, lr_rate, name='MultiStepLR'):\n",
        "    \"\"\"Multi-steps learning rate scheduler.\"\"\"\n",
        "    lr_steps_value = [initial_learning_rate]\n",
        "    for _ in range(len(lr_steps)):\n",
        "        lr_steps_value.append(lr_steps_value[-1] * lr_rate)\n",
        "    return tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "        boundaries=lr_steps, values=lr_steps_value)\n",
        "\n",
        "\n",
        "def CosineAnnealingLR_Restart(initial_learning_rate, t_period, lr_min):\n",
        "    \"\"\"Cosine annealing learning rate scheduler with restart.\"\"\"\n",
        "    return tf.keras.experimental.CosineDecayRestarts(\n",
        "        initial_learning_rate=initial_learning_rate,\n",
        "        first_decay_steps=t_period, t_mul=1.0, m_mul=1.0,\n",
        "        alpha=lr_min / initial_learning_rate)\n",
        "\n",
        "\n",
        "\n",
        "    # pretrain PSNR lr scheduler\n",
        "lr_scheduler_D = MultiStepLR(1e-4, [50000, 100000, 200000, 300000], 0.5)\n",
        "\n",
        "    # ESRGAN lr scheduler\n",
        "lr_scheduler_G = MultiStepLR(1e-4, [50000, 100000, 200000, 300000], 0.5)\n",
        "\n",
        "    # Cosine Annealing lr scheduler\n",
        "    # lr_scheduler = CosineAnnealingLR_Restart(2e-4, 250000, 1e-7)\n",
        "\n",
        "    ##############################\n",
        "    # Draw figure\n",
        "    ##############################\n",
        "N_iter = 1000000\n",
        "step_list = list(range(0, N_iter, 1000))\n",
        "lr_list = []\n",
        "for i in step_list:\n",
        "     current_lr = lr_scheduler_G(i).numpy()\n",
        "     lr_list.append(current_lr)\n",
        "\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "mpl.style.use('default')\n",
        "import seaborn\n",
        "seaborn.set(style='whitegrid')\n",
        "seaborn.set_context('paper')\n",
        "\n",
        "plt.figure(1)\n",
        "plt.subplot(111)\n",
        "plt.ticklabel_format(style='sci', axis='x', scilimits=(0, 0))\n",
        "plt.title('Title', fontsize=16, color='k')\n",
        "plt.plot(step_list, lr_list, linewidth=1.5, label='learning rate scheme')\n",
        "legend = plt.legend(loc='upper right', shadow=False)\n",
        "ax = plt.gca()\n",
        "labels = ax.get_xticks().tolist()\n",
        "for k, v in enumerate(labels):\n",
        "    labels[k] = str(int(v / 1000)) + 'K'\n",
        "ax.set_xticklabels(labels)\n",
        "ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.1e'))\n",
        "\n",
        "ax.set_ylabel('Learning rate')\n",
        "ax.set_xlabel('Iteration')\n",
        "fig = plt.gcf()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HSbqUHSjnN3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Functions:\n",
        "\n",
        "- Disc loss -> VGG19\n",
        "- Perceptual Loss\n",
        "- Relativistic Loss - Generator Loss\n",
        "- Pixel-wise Loss\n"
      ],
      "metadata": {
        "id": "y4DPxRh3n8sE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input, VGG19\n",
        "\n",
        "\n",
        "def PixelLoss(criterion='l1'):\n",
        "    \"\"\"pixel loss\"\"\"\n",
        "    if criterion == 'l1':\n",
        "        return tf.keras.losses.MeanAbsoluteError()\n",
        "    elif criterion == 'l2':\n",
        "        return tf.keras.losses.MeanSquaredError()\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'Loss type {} is not recognized.'.format(criterion))\n",
        "\n",
        "\n",
        "def ContentLoss(criterion='l1', output_layer=54, before_act=True):\n",
        "    \"\"\"content loss\"\"\"\n",
        "    if criterion == 'l1':\n",
        "        loss_func = tf.keras.losses.MeanAbsoluteError()\n",
        "    elif criterion == 'l2':\n",
        "        loss_func = tf.keras.losses.MeanSquaredError()\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'Loss type {} is not recognized.'.format(criterion))\n",
        "    vgg = VGG19(input_shape=(None, None, 3), include_top=False)\n",
        "\n",
        "    if output_layer == 22:  # Low level feature\n",
        "        pick_layer = 5\n",
        "    elif output_layer == 54:  # Hight level feature\n",
        "        pick_layer = 20\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'VGG output layer {} is not recognized.'.format(criterion))\n",
        "\n",
        "    if before_act:\n",
        "        vgg.layers[pick_layer].activation = None\n",
        "\n",
        "    fea_extrator = tf.keras.Model(vgg.input, vgg.layers[pick_layer].output)\n",
        "\n",
        "    @tf.function\n",
        "    def content_loss(hr, sr):\n",
        "        # the input scale range is [0, 1] (vgg is [0, 255]).\n",
        "        # 12.75 is rescale factor for vgg featuremaps.\n",
        "        preprocess_sr = preprocess_input(sr * 255.) / 12.75\n",
        "        preprocess_hr = preprocess_input(hr * 255.) / 12.75\n",
        "        sr_features = fea_extrator(preprocess_sr)\n",
        "        hr_features = fea_extrator(preprocess_hr)\n",
        "\n",
        "        return loss_func(hr_features, sr_features)\n",
        "\n",
        "    return content_loss\n",
        "\n",
        "\n",
        "def DiscriminatorLoss(gan_type='ragan'):\n",
        "    \"\"\"discriminator loss\"\"\"\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    sigma = tf.sigmoid\n",
        "\n",
        "    def discriminator_loss_ragan(hr, sr):\n",
        "        return 0.5 * (\n",
        "            cross_entropy(tf.ones_like(hr), sigma(hr - tf.reduce_mean(sr))) +\n",
        "            cross_entropy(tf.zeros_like(sr), sigma(sr - tf.reduce_mean(hr))))\n",
        "\n",
        "    def discriminator_loss(hr, sr):\n",
        "        real_loss = cross_entropy(tf.ones_like(hr), sigma(hr))\n",
        "        fake_loss = cross_entropy(tf.zeros_like(sr), sigma(sr))\n",
        "        return real_loss + fake_loss\n",
        "\n",
        "    if gan_type == 'ragan':\n",
        "        return discriminator_loss_ragan\n",
        "    elif gan_type == 'gan':\n",
        "        return discriminator_loss\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'Discriminator loss type {} is not recognized.'.format(gan_type))\n",
        "\n",
        "\n",
        "def GeneratorLoss(gan_type='ragan'):\n",
        "    \"\"\"generator loss\"\"\"\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    sigma = tf.sigmoid\n",
        "\n",
        "    def generator_loss_ragan(hr, sr):\n",
        "        return 0.5 * (\n",
        "            cross_entropy(tf.ones_like(sr), sigma(sr - tf.reduce_mean(hr))) +\n",
        "            cross_entropy(tf.zeros_like(hr), sigma(hr - tf.reduce_mean(sr))))\n",
        "\n",
        "    def generator_loss(hr, sr):\n",
        "        return cross_entropy(tf.ones_like(sr), sigma(sr))\n",
        "\n",
        "    if gan_type == 'ragan':\n",
        "        return generator_loss_ragan\n",
        "    elif gan_type == 'gan':\n",
        "        return generator_loss\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'Generator loss type {} is not recognized.'.format(gan_type))\n",
        "\n",
        "pixel_loss_fn = PixelLoss(\"l2\")\n",
        "fea_loss_fn = ContentLoss(\"l2\")\n",
        "gen_loss_fn = GeneratorLoss(\"ragan\")\n",
        "dis_loss_fn = DiscriminatorLoss(\"ragan\")"
      ],
      "metadata": {
        "id": "yBhHHpmnofX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this instead"
      ],
      "metadata": {
        "id": "JUnjYsivBWfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pixelwise_mse(y_true, y_pred):\n",
        "  mean_squared_error = tf.reduce_mean(tf.reduce_mean(\n",
        "      (y_true - y_pred)**2, axis=0))\n",
        "  return mean_squared_error\n",
        "\n",
        "def RelativisticAverageLoss(non_transformed_disc, type_=\"G\"):\n",
        "  \"\"\" Relativistic Average Loss based on RaGAN\n",
        "      Args:\n",
        "      non_transformed_disc: non activated discriminator Model\n",
        "      type_: type of loss to Ra loss to produce.\n",
        "             'G': Relativistic average loss for generator\n",
        "             'D': Relativistic average loss for discriminator\n",
        "  \"\"\"\n",
        "  loss = None\n",
        "\n",
        "  def D_Ra(x, y):\n",
        "    return non_transformed_disc(\n",
        "        x) - tf.reduce_mean(non_transformed_disc(y))\n",
        "\n",
        "  def loss_D(y_true, y_pred):\n",
        "    \"\"\"\n",
        "      Relativistic Average Loss for Discriminator\n",
        "      Args:\n",
        "        y_true: Real Image\n",
        "        y_pred: Generated Image\n",
        "    \"\"\"\n",
        "    real_logits = D_Ra(y_true, y_pred)\n",
        "    fake_logits = D_Ra(y_pred, y_true)\n",
        "    real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "        labels=tf.ones_like(real_logits), logits=real_logits))\n",
        "    fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "        labels=tf.zeros_like(fake_logits), logits=fake_logits))\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "  def loss_G(y_true, y_pred):\n",
        "    \"\"\"\n",
        "     Relativistic Average Loss for Generator\n",
        "     Args:\n",
        "       y_true: Real Image\n",
        "       y_pred: Generated Image\n",
        "    \"\"\"\n",
        "    real_logits = D_Ra(y_true, y_pred)\n",
        "    fake_logits = D_Ra(y_pred, y_true)\n",
        "    real_loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "        labels=tf.zeros_like(real_logits), logits=real_logits)\n",
        "    fake_loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "        labels=tf.ones_like(fake_logits), logits=fake_logits)\n",
        "    return real_loss + fake_loss\n",
        "  if type_ == \"G\":\n",
        "    loss = loss_G\n",
        "  elif type_ == \"D\":\n",
        "    loss = loss_D\n",
        "  return loss"
      ],
      "metadata": {
        "id": "DuoosTMJBUh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation\n",
        "\n",
        "1. Load dataset.\n",
        "2. Compile the Student Model.\n",
        "3. Load the Teacher model.\n",
        "4. Initialize optimizers.\n",
        "5. Execute adversarial training step."
      ],
      "metadata": {
        "id": "-2yMj47lLO7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Load dataset."
      ],
      "metadata": {
        "id": "1F4zEeOWL57l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n=5000\n",
        "lr_list = os.listdir(\"/content/drive/MyDrive/Image datasets/data/lr_images\")[:n]\n",
        "lr_list.sort\n",
        "\n",
        "lr_images = []\n",
        "for img in lr_list:\n",
        "    img_lr = cv2.imread(\"/content/drive/MyDrive/Image datasets/data/lr_images/\" + img)\n",
        "    img_lr = cv2.cvtColor(img_lr, cv2.COLOR_BGR2RGB)\n",
        "    lr_images.append(img_lr)\n",
        "\n",
        "\n",
        "hr_list = os.listdir(\"/content/drive/MyDrive/Image datasets/data/hr_images\")[:n]\n",
        "hr_list.sort\n",
        "\n",
        "hr_images = []\n",
        "for img in hr_list:\n",
        "    img_hr = cv2.imread(\"/content/drive/MyDrive/Image datasets/data/hr_images/\" + img)\n",
        "    img_hr = cv2.cvtColor(img_hr, cv2.COLOR_BGR2RGB)\n",
        "    hr_images.append(img_hr)\n",
        "\n",
        "lr_images = np.array(lr_images)\n",
        "hr_images = np.array(hr_images)"
      ],
      "metadata": {
        "id": "OkVoxYDOLOE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize input"
      ],
      "metadata": {
        "id": "MGCl9KctMBK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Scale values\n",
        "lr_images = lr_images / 255.\n",
        "hr_images = hr_images / 255.\n",
        "\n",
        "#Split into train and test sets\n",
        "lr_train, lr_test, hr_train, hr_test = train_test_split(lr_images, hr_images,\n",
        "                                                      test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "1PAOp7plME29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Compiling the Student model:"
      ],
      "metadata": {
        "id": "8476CEEKM6Kn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hr_shape = (hr_train.shape[1], hr_train.shape[2], hr_train.shape[3])\n",
        "lr_shape = (lr_train.shape[1], lr_train.shape[2], lr_train.shape[3])\n",
        "\n",
        "lr_ip = Input(shape=lr_shape)\n",
        "hr_ip = Input(shape=hr_shape)\n",
        "\n",
        "#generator = create_gen(lr_ip, num_res_block = 16)\n",
        "generator = create_gen(lr_ip, num_res_block = 8)\n",
        "#generator.summary()\n",
        "\n",
        "discriminator = create_disc(hr_ip)\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer= optimizer_D, metrics=['accuracy'])\n",
        "#discriminator.summary()\n",
        "\n",
        "vgg = build_vgg((128,128,3))\n",
        "#print(vgg.summary())\n",
        "vgg.trainable = False\n",
        "\n",
        "gan_model = create_comb(generator, discriminator, vgg, lr_ip, hr_ip)\n",
        "\n",
        "# Cimpilation Parameters:\n",
        "# Loss: binary_crossentropy\n",
        "# Content: feature map obtained by the j-th convolution (after activation)\n",
        "# before the i-th maxpooling layer within the VGG19 network.\n",
        "# MSE between the feature representations of a reconstructed image\n",
        "# and the reference image.\n",
        "gan_model.compile(loss=[\"binary_crossentropy\", \"mse\"], loss_weights=[1e-3, 1], optimizer=optimizer_G)\n",
        "gan_model.summary()"
      ],
      "metadata": {
        "id": "6PIrpBqmM_1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Load the Teacher:"
      ],
      "metadata": {
        "id": "OVy4lXMCSyD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from numpy.random import randint\n",
        "\n",
        "Teacher = load_model('/content/drive/MyDrive/Image datasets/data/models/gen7_e_40_9.04.h5', compile=True)"
      ],
      "metadata": {
        "id": "N100ek8SS2oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Initialize optimizers."
      ],
      "metadata": {
        "id": "4uZcelbhTGq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_G = tf.keras.optimizers.Adam(learning_rate=lr_scheduler_G,\n",
        "                                       beta_1=0.9,\n",
        "                                       beta_2=0.999)\n",
        "optimizer_G.build\n",
        "\n",
        "optimizer_D = tf.keras.optimizers.Adam(learning_rate=lr_scheduler_D,\n",
        "                                       beta_1=0.9,\n",
        "                                       beta_2=0.999)\n",
        "optimizer_D.build"
      ],
      "metadata": {
        "id": "qcSn0-ojnsPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Organizing Batches"
      ],
      "metadata": {
        "id": "eG9gWsjKR_hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "train_lr_batches = []\n",
        "train_hr_batches = []\n",
        "for it in range(int(hr_train.shape[0] / batch_size)):\n",
        "    start_idx = it * batch_size\n",
        "    end_idx = start_idx + batch_size\n",
        "    train_hr_batches.append(hr_train[start_idx:end_idx])\n",
        "    train_lr_batches.append(lr_train[start_idx:end_idx])"
      ],
      "metadata": {
        "id": "x7IGKAiRSCQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combining the Pieces:\n",
        "\n",
        "Model Training Step Function"
      ],
      "metadata": {
        "id": "XGfJ0CtJSIPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = tf.keras.losses.MeanSquaredError(reduction=\"none\")\n",
        "metric_fn = tf.keras.metrics.Mean()\n",
        "student_psnr = tf.keras.metrics.Mean()\n",
        "teacher_psnr = tf.keras.metrics.Mean()\n",
        "\n",
        "ra_generator = utils.RelativisticAverageLoss(\n",
        "        teacher_disc, type_=\"G\")\n",
        "ra_discriminator = utils.RelativisticAverageLoss(\n",
        "        teacher_disc, type_=\"D\")\n",
        "perceptual_loss = utils.PerceptualLoss(\n",
        "        weights=\"imagenet\",\n",
        "        input_shape=hr_size,\n",
        "        loss_type=\"L2\")\n",
        "student_psnr = tf.keras.metrics.Mean()\n",
        "teacher_psnr = tf.keras.metrics.Mean()"
      ],
      "metadata": {
        "id": "Lz3fovu9hTKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define vars!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "alpha = !!float 1e-4\n",
        "lambda = !!float 5e-2\n",
        "teacher_disc = discriminator\n",
        "generator_metric = tf.keras.metrics.Mean()\n",
        "discriminator_metric = tf.keras.metrics.Mean()\n",
        "dummy_optimizer = tf.optimizers.Adam()\n",
        "\n",
        "def preprocess_input(image):\n",
        "  image = image[..., ::-1]\n",
        "  mean = -tf.constant([103.939, 116.779, 123.68])\n",
        "  return tf.nn.bias_add(image, mean)\n",
        "\n",
        "\n",
        "def step_fn(image_lr, image_hr):\n",
        "  with tf.GradientTape() as gen_Tape, tf.GradientTape() as disc_tape:\n",
        "    teacher_fake = Teacher.predict_on_batch(image_lr)\n",
        "    teacher_fake = tf.clip_by_value(teacher_fake, 0, 255)\n",
        "\n",
        "    student_fake = gan_model.train_on_batch(image_lr)\n",
        "    student_fake = tf.clip_by_value(teacher_fake, 0, 255)\n",
        "\n",
        "    image_hr = tf.clip_by_value(image_hr,0,255)\n",
        "\n",
        "    psnr = tf.image.psnr(student_fake, image_hr, max_val=255.0)\n",
        "    student_psnr = tf.reduce_mean(psnr)\n",
        "\n",
        "    psnr = tf.image.psnr(teacher_fake, image_hr, max_val=255.0)\n",
        "    teacher_psnr = tf.reduce_mean(psnr)\n",
        "\n",
        "    mse_loss = pixelwise_mse(teacher_fake, student_fake)\n",
        "\n",
        "    image_lr = preprocess_input(image_lr)\n",
        "    image_hr = preprocess_input(image_hr)\n",
        "    student_fake = preprocess_input(student_fake)\n",
        "    teacher_fake = preprocess_input(teacher_fake)\n",
        "\n",
        "    student_ra_loss = ra_generator(teacher_fake, student_fake)\n",
        "    discriminator_loss = ra_discriminator(teacher_fake, student_fake)\n",
        "    discriminator_metric(discriminator_loss)\n",
        "        discriminator_loss = tf.reduce_mean(\n",
        "            discriminator_loss) * (1.0 / batch_size)\n",
        "    percep_loss = perceptual_loss(image_hr, student_fake)\n",
        "    generator_loss = lambda_ * percep_loss + alpha * student_ra_loss + (1 - alpha) * mse_loss\n",
        "    generator_metric(generator_loss)\n",
        "    generator_loss = tf.reduce_mean(\n",
        "            generator_loss) * (1.0 / batch_size)\n",
        "\n",
        "\n",
        "    generator_gradient = gen_tape.gradient(\n",
        "          generator_loss, student.trainable_variables)\n",
        "\n",
        "    discriminator_gradient = disc_tape.gradient(\n",
        "          discriminator_loss, teacher_disc.trainable_variables)\n",
        "\n",
        "    generator_op = generator_optimizer.apply_gradients(\n",
        "          zip(generator_gradient, student.trainable_variables))\n",
        "    discriminator_op = discriminator_optimizer.apply_gradients(\n",
        "          zip(discriminator_gradient, teacher_disc.trainable_variables))\n",
        "\n",
        "    with tf.control_dependencies(\n",
        "              [generator_op, discriminator_op]):\n",
        "        return tf.cast(discriminator_optimizer.iterations, tf.float32)\n",
        "\n",
        "# finish return and full loop\n",
        "\n",
        "@tf.function\n",
        "    def train_step(image_lr, image_hr):\n",
        "      \"\"\"\n",
        "        In Graph Function to assign trainer function to\n",
        "        replicate among worker nodes.\n",
        "        Args:\n",
        "          image_lr: Distributed batch of Low Resolution Images\n",
        "          image_hr: Distributed batch of High Resolution Images\n",
        "      \"\"\"\n",
        "      distributed_metric = step_fn(image_lr, image_hr)\n",
        "      mean_metric = distributed_metric\n",
        "      return mean_metric\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "55V9ZnV7UdZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "for e in range(epochs):\n",
        "\n",
        "    fake_label = np.zeros((batch_size, 1)) # Assign a label of 0 to all fake (generated images)\n",
        "    real_label = np.ones((batch_size,1)) # Assign a label of 1 to all real images.\n",
        "\n",
        "    #gen and disc losses.\n",
        "    g_losses = []\n",
        "    d_losses = []\n",
        "\n",
        "\n",
        "    for b in tqdm(range(len(train_hr_batches))):\n",
        "        lr_imgs = train_lr_batches[b] #Fetch a batch of LR images for training\n",
        "        hr_imgs = train_hr_batches[b] #Fetch a batch of HR images for training\n",
        "\n",
        "        fake_imgs = generator.predict_on_batch(lr_imgs) #Fake images\n",
        "\n",
        "        #training the discriminator on fake and real HR images.\n",
        "        discriminator.trainable = True\n",
        "        d_loss_gen = discriminator.train_on_batch(fake_imgs, fake_label)\n",
        "        d_loss_real = discriminator.train_on_batch(hr_imgs, real_label)\n",
        "\n",
        "        #training the generator by fixing discriminator as non-trainable\n",
        "        discriminator.trainable = False\n",
        "\n",
        "        metric = train_step(lr_imgs, hr_imgs)\n",
        "\n",
        "        d_losses.append(discriminator_loss)\n",
        "        g_losses.append(generator_loss)\n",
        "\n",
        "\n",
        "        clear_output()\n",
        "\n",
        "    #Convert the list of losses to an array\n",
        "    g_losses = np.array(g_losses)\n",
        "    d_losses = np.array(d_losses)\n",
        "\n",
        "    #Calculate the average losses for generator and discriminator\n",
        "    g_loss = np.sum(g_losses, axis=0) / len(g_losses)\n",
        "    d_loss = np.sum(d_losses, axis=0) / len(d_losses)\n",
        "\n",
        "    print(\"epoch:\", e+1 ,\"g_loss:\", g_loss, \"d_loss:\", d_loss)\n",
        "    #generator.save(\"/content/drive/MyDrive/Image datasets/data/models/Student/gen1_e_\"+ str(e+1) + \"_\" + str(\"{:.2f}\".format(round(g_loss,2))) +\".h5\")\n",
        "\n",
        "    if (e+1) % 5 == 0:\n",
        "        #Save the generator after every 5 epochs\n",
        "        generator.save(\"/content/drive/MyDrive/Image datasets/data/models/Student/gen1_e_\"+ str(e+1) + \"_\" + str(\"{:.2f}\".format(round(g_loss,2))) +\".h5\")"
      ],
      "metadata": {
        "id": "nO6qKkALSHw2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}